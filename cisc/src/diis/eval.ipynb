{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05bc3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"HF_HOME\"] = \"/home/yandex/APDL2425a/group_12/gorodissky/.cache/huggingface\"\n",
    "print(f\"HF_HOME set to:\\t\\t {os.environ['HF_HOME']}\")\n",
    "import torch\n",
    "\n",
    "print(torch.__version__)\n",
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f65032",
   "metadata": {},
   "outputs": [],
   "source": [
    "from cisc.src.post_processing import aggregators, run_eval_lib\n",
    "import json\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', message='Labels passed were')\n",
    "\n",
    "aggregator_configs = [\n",
    "    aggregators.AggregatorConfig(\n",
    "        aggregator_type=aggregators.AggregatorType.SC,\n",
    "        norm_type=aggregators.NormalizationType.NONE,\n",
    "    ),\n",
    "    aggregators.AggregatorConfig(\n",
    "        aggregator_type=aggregators.AggregatorType.CISC,\n",
    "        norm_type=aggregators.NormalizationType.SOFTMAX,\n",
    "        temperature=0.2,  # This value is taken from the CISC paper.\n",
    "        confidence_col_name=\"logit_confidence\",  # P(True) in the paper.\n",
    "    )\n",
    "]\n",
    "PATH = \"/home/yandex/APDL2425a/group_12/gorodissky/google-research/cisc/output/Qwen2.5-7B-Instruct/confidence/2026_01_11_14:43/MMLU\"\n",
    "with open(os.path.join(PATH, \"experiment_conf.json\"), \"r\") as f:\n",
    "    expr_config = json.load(f)\n",
    "sample_sizes = range(1, 6)\n",
    "\n",
    "stats = run_eval_lib.calculate_stats_for_model_and_dataset_path(\n",
    "    expr_config[\"tag\"],\n",
    "    PATH,\n",
    "    filter_answers=False,\n",
    "    round_negative_conf_to_zero=False,\n",
    "    re_compute_is_correct=False,\n",
    "    aggregator_configs=aggregator_configs,\n",
    "    traces_lens=sample_sizes,\n",
    "    num_bootstrap=500,\n",
    "    return_per_question_scores=False,\n",
    ").score_stats\n",
    "\n",
    "for metric_name, metric_scores in stats.items():\n",
    "    print(f\"{metric_name}: {metric_scores}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b634aa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs sample size\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 4))\n",
    "mean_number_of_traces = stats.pop(\"DIIS_mean_num_traces\")\n",
    "for metric_name, metric_scores in stats.items():\n",
    "    if 'budget' in metric_name:\n",
    "        continue\n",
    "    if \"CISC\" in metric_name:\n",
    "        if \"DIIS\" in metric_name:\n",
    "            axes[0].plot( mean_number_of_traces, metric_scores, linestyle='--', marker='o', label=metric_name, color='orange')\n",
    "        else:\n",
    "            axes[0].plot(sample_sizes, metric_scores, label=metric_name, linestyle='-', marker='o', color='orange')\n",
    "    else: # SC\n",
    "        if \"DIIS\" in metric_name:\n",
    "            axes[1].plot( mean_number_of_traces, metric_scores, linestyle='--', marker='o', label=metric_name, color='blue')\n",
    "        else:\n",
    "            axes[1].plot(sample_sizes, metric_scores, label=metric_name, linestyle='-', marker='o', color='blue')\n",
    "            \n",
    "for i in range(2):\n",
    "    axes[i].set_xlabel('Sample Size')\n",
    "    axes[i].set_ylabel('Accuracy')\n",
    "    axes[i].legend()\n",
    "    axes[i].grid()\n",
    "\n",
    "# create table for effiecency \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eceede7",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes =   plt.subplots(2, figsize=(10, 3))\n",
    "for i in range(2):\n",
    "    axes[i].axis('off')\n",
    "DIIS_budget = stats[\"DIIS_total_budget\"]\n",
    "\n",
    "cell_text = [ f\"{stats['DIIS_CISC_logit_confidence_SOFTMAX_0.2'][0] / DIIS_budget:.4f}\"]\n",
    "for sample_size in sample_sizes:\n",
    "    budget = sample_size * 128\n",
    "    efficiency = stats[\"CISC_logit_confidence_SOFTMAX_0.2\"][sample_size - 1] / budget\n",
    "    cell_text.append(f\"{efficiency:.4f}\")\n",
    "col_labels = [\"DIIS_CISC\", \"CISC (1)\", \"CISC (2)\", \"CISC (3)\", \"CISC (4)\", \"CISC (5)\",]\n",
    "row_labels = [\"Acc / Budget\"]\n",
    "table = axes[0].table(cellText=[cell_text], colLabels=col_labels, rowLabels=row_labels, loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)  \n",
    "\n",
    "cell_text = [ f\"{stats['DIIS_SC_NONE'][0] / DIIS_budget:.4f}\"]\n",
    "for sample_size in sample_sizes:\n",
    "    budget = sample_size * 128\n",
    "    efficiency = stats[\"SC_NONE\"][sample_size - 1] / budget\n",
    "    cell_text.append(f\"{efficiency:.4f}\")\n",
    "col_labels = [\"DIIS_SC\", \"SC (1)\", \"SC (2)\", \"SC (3)\", \"SC (4)\", \"SC (5)\",]\n",
    "row_labels = [\"Acc / Budget\"]\n",
    "table = axes[1].table(cellText=[cell_text], colLabels=col_labels, rowLabels=row_labels, loc='center')\n",
    "table.auto_set_font_size(False)\n",
    "table.set_fontsize(12)\n",
    "table.scale(1.5, 1.5)   \n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "366dfb55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "base_dir = \"/home/yandex/APDL2425a/group_12/gorodissky/google-research/cisc/output/\"\n",
    "with open(base_dir + \"Qwen2.5-7B-Instruct/confidence/2026_01_11_14:43/MMLU/experiment_output.pkl\", \"rb\") as f:\n",
    "    results = pickle.load(f)\n",
    "\n",
    "df = results.get_results_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a7747e",
   "metadata": {},
   "outputs": [],
   "source": [
    "difficulties = df.groupby('question_id').agg({'difficulty': 'first'})\n",
    "print(\"mean:\", difficulties.mean().item())\n",
    "print(\"std:\", difficulties.std().item())\n",
    "print(\"max:\", difficulties.max().item())\n",
    "print(\"min:\", difficulties.min().item())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DIIS venv",
   "language": "python",
   "name": "diis-venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
